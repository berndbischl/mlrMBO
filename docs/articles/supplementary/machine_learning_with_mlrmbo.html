<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Machine learning with mlrMBO: Tuning hyperparameters with model-based optimization • mlrMBO</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../../pkgdown.css" rel="stylesheet">
<script src="../../jquery.sticky-kit.min.js"></script><script src="../../pkgdown.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../../index.html">mlrMBO</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../../articles/mlrMBO.html">
    <span class="fa fa-bolt"></span>
     
    Quickstart
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-file-text-o"></span>
     
    Topics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../articles/supplementary/mixed_space_optimization.html">Mixed Space Optimization</a>
    </li>
    <li>
      <a href="../../articles/supplementary/parallelization.html">Parallelization</a>
    </li>
    <li>
      <a href="../../articles/supplementary/noisy_optimization.html">Noisy Optimization</a>
    </li>
    <li>
      <a href="../../articles/supplementary/infill_criteria.html">Infill Criteria</a>
    </li>
    <li>
      <a href="../../articles/supplementary/machine_learning_with_mlrmbo.html">Machine learning with mlrMBO</a>
    </li>
    <li>
      <a href="../../articles/supplementary/human_in_the_loop_MBO.html">Human-in-the-loop MBO</a>
    </li>
  </ul>
</li>
<li>
  <a href="../../reference/index.html">
    <span class="fa fa-book"></span>
     
    Reference
  </a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/mlr-org/mlrMBO">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>Machine learning with mlrMBO: Tuning hyperparameters with model-based optimization</h1>
            
          </div>

    
    
<div class="contents">
<div id="purpose" class="section level2">
<h2 class="hasAnchor">
<a href="#purpose" class="anchor"></a>Purpose</h2>
<p>This Vignette is supposed to give you an introduction on how to use <code>mlrMBO</code> for hyperparameter tuning in the context of machine learning using the <code>mlr</code> package.</p>
</div>
<div id="mlr" class="section level2">
<h2 class="hasAnchor">
<a href="#mlr" class="anchor"></a><code>mlr</code>
</h2>
<p>For the purpose of hyperparameter tuning, we will use the <a href="/mlr-tutorial/devel/html/index.html"><code>mlr</code></a> package. <code>mlr</code> provides a framework for machine learning in R that comes with a broad range of machine learning functionalities and is easily extendable. One possible approach is to use <code>mlr</code> to train a learner and evaluate its performance for a given hyperparameter configuration in the objective function. Alternatively, we can access <code>mlrMBO</code>’s model-based optimization directly using <a href="/mlr-tutorial/devel/html/tune/index.html"><code>mlr</code>’s tuning functionalities</a>. This yields the benefit of integrating hyperparameter tuning with model-based optimization into your machine learning experiments without any overhead.</p>
</div>
<div id="preparations" class="section level2">
<h2 class="hasAnchor">
<a href="#preparations" class="anchor"></a>Preparations</h2>
<p>First, we load the required packages. Next, we configure <code>mlr</code> to suppress the learner output to improve output readability. Additionally, we define a global variable giving the number of tuning iterations. Note that this number is set (very) low to reduce runtime.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(mlrMBO)
<span class="kw">library</span>(mlr)

<span class="kw"><a href="http://www.rdocumentation.org/packages/mlr/topics/configureMlr">configureMlr</a></span>(<span class="dt">on.learner.warning =</span> <span class="st">"quiet"</span>, <span class="dt">show.learner.output =</span> <span class="ot">FALSE</span>)

iters =<span class="st"> </span><span class="dv">5</span></code></pre></div>
</div>
<div id="custom-objective-function-to-evaluate-performance" class="section level2">
<h2 class="hasAnchor">
<a href="#custom-objective-function-to-evaluate-performance" class="anchor"></a>1 Custom objective function to evaluate performance</h2>
<p>As an example, we tune the <code>cost</code> and the <code>gamma</code> parameter of a rbf-SVM on the <a href="https://en.wikipedia.org/wiki/Iris_flower_data_set">Iris data</a>. First, we define the parameter set. Note that the transformations added in the <code>trafo</code> argument mean, that we tune the parameters on a logarithmic scale.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">par.set =<span class="st"> </span><span class="kw">makeParamSet</span>(
  <span class="kw">makeNumericParam</span>(<span class="st">"cost"</span>, -<span class="dv">15</span>, <span class="dv">15</span>, <span class="dt">trafo =</span> function(x) <span class="dv">2</span>^x),
  <span class="kw">makeNumericParam</span>(<span class="st">"gamma"</span>, -<span class="dv">15</span>, <span class="dv">15</span>, <span class="dt">trafo =</span> function(x) <span class="dv">2</span>^x)
)</code></pre></div>
<p>Next, we define the objective function. First, we define a learner and set its hyperparameters by using <code>makeLearner</code>. To evaluate its performance we use the <code>resample</code> function which automatically takes care of fitting the model and evaluating it on a test set. In this example, resampling is done using 3-fold cross-validation, by passing the <code>ResampleDesc</code> object <code>cv3</code>, that comes predefined with <code>mlr</code>, as an argument to <code>resample</code>. The measure to be optimized can be specified (e.g by passing <code>measures = ber</code>, for the <em>balanced error rate</em>), however <code>mlr</code> has a default for each task type. For classification the <code>mmce</code>(Mean misclassification rate) is the default. Like <a href="mixed_space_optimization.html" title="Mixed Space Optimization">in this example</a>, we set <code>minimize = TRUE</code> and <code>has.simple.signature = FALSE</code>. Note that the <code>iris.task</code> is provided automatically when loading <code>mlr</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">svm =<span class="st"> </span><span class="kw">makeSingleObjectiveFunction</span>(<span class="dt">name =</span> <span class="st">"svm.tuning"</span>,
  <span class="dt">fn =</span> function(x) {
    lrn =<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/mlr/topics/makeLearner">makeLearner</a></span>(<span class="st">"classif.svm"</span>, <span class="dt">par.vals =</span> x)
    <span class="kw"><a href="http://www.rdocumentation.org/packages/mlr/topics/resample">resample</a></span>(lrn, iris.task, cv3, <span class="dt">show.info =</span> <span class="ot">FALSE</span>)$aggr
  },
  <span class="dt">par.set =</span> par.set,
  <span class="dt">noisy =</span> <span class="ot">TRUE</span>,
  <span class="dt">has.simple.signature =</span> <span class="ot">FALSE</span>,
  <span class="dt">minimize =</span> <span class="ot">TRUE</span>
)</code></pre></div>
<p>Now we create a default <code>MBOControl</code> object and tune the rbf-SVM.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ctrl =<span class="st"> </span><span class="kw"><a href="../../reference/makeMBOControl.html">makeMBOControl</a></span>()
ctrl =<span class="st"> </span><span class="kw"><a href="../../reference/setMBOControlTermination.html">setMBOControlTermination</a></span>(ctrl, <span class="dt">iters =</span> iters)

res =<span class="st"> </span><span class="kw"><a href="../../reference/mbo.html">mbo</a></span>(svm, <span class="dt">control =</span> ctrl, <span class="dt">show.info =</span> <span class="ot">FALSE</span>)
<span class="kw">print</span>(res)
## Recommended parameters:
## cost=7.01; gamma=-3.21
## Objective: y = 0.033
## 
## Optimization path
## 8 + 5 entries in total, displaying last 10 (or less):
##          cost       gamma          y dob eol error.message exec.time
## 4    1.980396   7.0965714 0.64666667   0  NA          &lt;NA&gt;     0.081
## 5    9.567881  -2.0376947 0.09333333   0  NA          &lt;NA&gt;     0.079
## 6  -11.411875   9.2000031 0.78666667   0  NA          &lt;NA&gt;     0.086
## 7   13.790890  13.3973753 0.73333333   0  NA          &lt;NA&gt;     0.082
## 8  -10.864032 -11.6256564 0.70666667   0  NA          &lt;NA&gt;     0.086
## 9   -7.169453  -3.2438288 0.70666667   1  NA          &lt;NA&gt;     0.081
## 10   4.776882  -1.4930382 0.06666667   2  NA          &lt;NA&gt;     0.086
## 11   7.007218  -3.2128683 0.03333333   3  NA          &lt;NA&gt;     0.093
## 12   8.618027  -4.7439627 0.04666667   4  NA          &lt;NA&gt;     0.088
## 13   5.676042   0.3092058 0.06000000   5  NA          &lt;NA&gt;     0.085
##             cb error.model train.time  prop.type propose.time         se
## 4           NA        &lt;NA&gt;         NA initdesign           NA         NA
## 5           NA        &lt;NA&gt;         NA initdesign           NA         NA
## 6           NA        &lt;NA&gt;         NA initdesign           NA         NA
## 7           NA        &lt;NA&gt;         NA initdesign           NA         NA
## 8           NA        &lt;NA&gt;         NA initdesign           NA         NA
## 9  -0.03268684        &lt;NA&gt;      0.262  infill_cb        0.160 0.10408864
## 10 -0.09869215        &lt;NA&gt;      0.720  infill_cb        0.080 0.16880860
## 11 -0.03984242        &lt;NA&gt;      0.043  infill_cb        0.081 0.06884957
## 12 -0.02613630        &lt;NA&gt;      0.068  infill_cb        0.096 0.09058801
## 13 -0.01333824        &lt;NA&gt;      0.177  infill_cb        0.078 0.10805501
##          mean lambda
## 4          NA     NA
## 5          NA     NA
## 6          NA     NA
## 7          NA     NA
## 8          NA     NA
## 9  0.07140180      1
## 10 0.07011645      1
## 11 0.02900716      1
## 12 0.06445171      1
## 13 0.09471677      1
res$x
## $cost
## [1] 7.007218
## 
## $gamma
## [1] -3.212868
res$y
## [1] 0.03333333
op =<span class="st"> </span><span class="kw">as.data.frame</span>(res$opt.path)
<span class="kw">plot</span>(<span class="kw">cummin</span>(op$y), <span class="dt">type =</span> <span class="st">"l"</span>, <span class="dt">ylab =</span> <span class="st">"mmce"</span>, <span class="dt">xlab =</span> <span class="st">"iteration"</span>)</code></pre></div>
<p><img src="machine_learning_with_mlrmbo_files/figure-html/unnamed-chunk-1-1.svg" width="672"></p>
</div>
<div id="using-mlrs-tuning-interface" class="section level2">
<h2 class="hasAnchor">
<a href="#using-mlrs-tuning-interface" class="anchor"></a>2 Using <code>mlr</code>’s tuning interface</h2>
<p>Instead of defining an objective function where the learner’s performance is evaluated, we can make use of model-based optimization directly from <code>mlr</code>. We just create a <code>TuneControl</code> object, passing the <code>MBOControl</code> object to it. Then we call <a href="/mlr-tutorial/devel/html/tune/index.html"><code>tuneParams</code></a> to tune the hyperparameters.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ctrl =<span class="st"> </span><span class="kw"><a href="../../reference/makeMBOControl.html">makeMBOControl</a></span>()
ctrl =<span class="st"> </span><span class="kw"><a href="../../reference/setMBOControlTermination.html">setMBOControlTermination</a></span>(ctrl, <span class="dt">iters =</span> iters)
tune.ctrl =<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/mlr/topics/makeTuneControlMBO">makeTuneControlMBO</a></span>(<span class="dt">mbo.control =</span> ctrl)
res =<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/mlr/topics/tuneParams">tuneParams</a></span>(<span class="kw"><a href="http://www.rdocumentation.org/packages/mlr/topics/makeLearner">makeLearner</a></span>(<span class="st">"classif.svm"</span>), iris.task, cv3, <span class="dt">par.set =</span> par.set, <span class="dt">control =</span> tune.ctrl,
  <span class="dt">show.info =</span> <span class="ot">FALSE</span>)
<span class="kw">print</span>(res)
## Tune result:
## Op. pars: cost=10.6; gamma=0.0575
## mmce.test.mean=0.0466667
res$x
## $cost
## [1] 10.59798
## 
## $gamma
## [1] 0.0574858
res$y
## mmce.test.mean 
##     0.04666667
op.y =<span class="st"> </span><span class="kw">getOptPathY</span>(res$opt.path)
<span class="kw">plot</span>(<span class="kw">cummin</span>(op.y), <span class="dt">type =</span> <span class="st">"l"</span>, <span class="dt">ylab =</span> <span class="st">"mmce"</span>, <span class="dt">xlab =</span> <span class="st">"iteration"</span>)</code></pre></div>
<p><img src="machine_learning_with_mlrmbo_files/figure-html/mlr_tuning-1.svg" width="672"></p>
</div>
<div id="hierarchical-mixed-space-optimization" class="section level2">
<h2 class="hasAnchor">
<a href="#hierarchical-mixed-space-optimization" class="anchor"></a>Hierarchical mixed space optimization</h2>
<p>In many cases, the hyperparameter space is not just numerical but mixed and often even hierarchical. This can easily be done out-of-the-box and needs no adaption to our previous example. (Recall that a suitable surrogate model is chosen automatically, as explained <a href="../mlrMBO.html#surrogate-model">here</a>.) To demonstrate this, we tune the <code>cost</code> and the <code>kernel</code> parameter of a SVM. When <code>kernel</code> takes the <code>radial</code> value, <code>gamma</code> needs to be specified. For a <code>polynomial</code> kernel, the <code>degree</code> needs to be specified.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">par.set =<span class="st"> </span><span class="kw">makeParamSet</span>(
  <span class="kw">makeDiscreteParam</span>(<span class="st">"kernel"</span>, <span class="dt">values =</span> <span class="kw">c</span>(<span class="st">"radial"</span>, <span class="st">"polynomial"</span>, <span class="st">"linear"</span>)),
  <span class="kw">makeNumericParam</span>(<span class="st">"cost"</span>, -<span class="dv">15</span>, <span class="dv">15</span>, <span class="dt">trafo =</span> function(x) <span class="dv">2</span>^x),
  <span class="kw">makeNumericParam</span>(<span class="st">"gamma"</span>, -<span class="dv">15</span>, <span class="dv">15</span>, <span class="dt">trafo =</span> function(x) <span class="dv">2</span>^x, <span class="dt">requires =</span> <span class="kw">quote</span>(kernel ==<span class="st"> "radial"</span>)),
  <span class="kw">makeIntegerParam</span>(<span class="st">"degree"</span>, <span class="dt">lower =</span> <span class="dv">1</span>, <span class="dt">upper =</span> <span class="dv">4</span>, <span class="dt">requires =</span> <span class="kw">quote</span>(kernel ==<span class="st"> "polynomial"</span>))
)</code></pre></div>
<p>Now we can just repeat the setup from the previous example and tune the hyperparameters.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ctrl =<span class="st"> </span><span class="kw"><a href="../../reference/makeMBOControl.html">makeMBOControl</a></span>()
ctrl =<span class="st"> </span><span class="kw"><a href="../../reference/setMBOControlTermination.html">setMBOControlTermination</a></span>(ctrl, <span class="dt">iters =</span> iters)
tune.ctrl =<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/mlr/topics/makeTuneControlMBO">makeTuneControlMBO</a></span>(<span class="dt">mbo.control =</span> ctrl)
res =<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/mlr/topics/tuneParams">tuneParams</a></span>(<span class="kw"><a href="http://www.rdocumentation.org/packages/mlr/topics/makeLearner">makeLearner</a></span>(<span class="st">"classif.svm"</span>), iris.task, cv3, <span class="dt">par.set =</span> par.set, <span class="dt">control =</span> tune.ctrl,
  <span class="dt">show.info =</span> <span class="ot">FALSE</span>)</code></pre></div>
</div>
<div id="parallelization-and-multi-point-proposals" class="section level2">
<h2 class="hasAnchor">
<a href="#parallelization-and-multi-point-proposals" class="anchor"></a>Parallelization and multi-point proposals</h2>
<p>We can easily add multi-point proposals and parallelize it using the <code>parallelMap</code> package. (Note that the chosen <em>multicore</em> back-end for parallelization does not work on windows machines. Please refer to the <a href="parallelization.html">parallelization section</a> for details on parallelization and multi point proposals.) In each iteration, we propose as many points as CPUs used for parallelization. As infill criterion we use Expected Improvement.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(parallelMap)
ncpus =<span class="st"> </span>2L

ctrl =<span class="st"> </span><span class="kw"><a href="../../reference/makeMBOControl.html">makeMBOControl</a></span>(<span class="dt">propose.points =</span> ncpus)
ctrl =<span class="st"> </span><span class="kw"><a href="../../reference/setMBOControlTermination.html">setMBOControlTermination</a></span>(ctrl, <span class="dt">iters =</span> iters)
ctrl =<span class="st"> </span><span class="kw"><a href="../../reference/setMBOControlInfill.html">setMBOControlInfill</a></span>(ctrl, <span class="dt">crit =</span> crit.ei)
ctrl =<span class="st"> </span><span class="kw"><a href="../../reference/setMBOControlMultiPoint.html">setMBOControlMultiPoint</a></span>(ctrl, <span class="dt">method =</span> <span class="st">"cl"</span>, <span class="dt">cl.lie =</span> min)
tune.ctrl =<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/mlr/topics/makeTuneControlMBO">makeTuneControlMBO</a></span>(<span class="dt">mbo.control =</span> ctrl)
<span class="kw"><a href="http://www.rdocumentation.org/packages/parallelMap/topics/parallelStart">parallelStartMulticore</a></span>(<span class="dt">cpus =</span> ncpus)
## Starting parallelization in mode=multicore with cpus=2.
res =<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/mlr/topics/tuneParams">tuneParams</a></span>(<span class="kw"><a href="http://www.rdocumentation.org/packages/mlr/topics/makeLearner">makeLearner</a></span>(<span class="st">"classif.svm"</span>), iris.task, cv3, <span class="dt">par.set =</span> par.set, <span class="dt">control =</span> tune.ctrl, <span class="dt">show.info =</span> <span class="ot">FALSE</span>)
## Mapping in parallel: mode = multicore; cpus = 2; elements = 16.
## Mapping in parallel: mode = multicore; cpus = 2; elements = 2.
## Mapping in parallel: mode = multicore; cpus = 2; elements = 2.
## Mapping in parallel: mode = multicore; cpus = 2; elements = 2.
## Mapping in parallel: mode = multicore; cpus = 2; elements = 2.
## Mapping in parallel: mode = multicore; cpus = 2; elements = 2.
<span class="kw"><a href="http://www.rdocumentation.org/packages/parallelMap/topics/parallelStop">parallelStop</a></span>()
## Stopped parallelization. All cleaned up.</code></pre></div>
</div>
<div id="usecase-pipeline-configuration" class="section level2">
<h2 class="hasAnchor">
<a href="#usecase-pipeline-configuration" class="anchor"></a>Usecase: Pipeline configuration</h2>
<p>It is also possible to tune a whole machine learning pipeline, i.e. preprocessing and model configuration. The example pipeline is: * Feature filtering based on an ANOVA test or covariance, such that between 50% and 100% of the features remain. * Select either a SVM or a naive Bayes classifier. * Tune parameters of the selected classifier.</p>
<p>First, we define the parameter space:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">par.set =<span class="st"> </span><span class="kw">makeParamSet</span>(
  <span class="kw">makeDiscreteParam</span>(<span class="st">"fw.method"</span>, <span class="dt">values =</span> <span class="kw">c</span>(<span class="st">"anova.test"</span>, <span class="st">"variance"</span>)),
  <span class="kw">makeNumericParam</span>(<span class="st">"fw.perc"</span>, <span class="dt">lower =</span> <span class="fl">0.1</span>, <span class="dt">upper =</span> <span class="dv">1</span>),
  <span class="kw">makeDiscreteParam</span>(<span class="st">"selected.learner"</span>, <span class="dt">values =</span> <span class="kw">c</span>(<span class="st">"classif.svm"</span>, <span class="st">"classif.naiveBayes"</span>)),
  <span class="kw">makeNumericParam</span>(<span class="st">"classif.svm.cost"</span>, -<span class="dv">15</span>, <span class="dv">15</span>, <span class="dt">trafo =</span> function(x) <span class="dv">2</span>^x,
    <span class="dt">require =</span> <span class="kw">quote</span>(selected.learner ==<span class="st"> "classif.svm"</span>)),
  <span class="kw">makeNumericParam</span>(<span class="st">"classif.svm.gamma"</span>, -<span class="dv">15</span>, <span class="dv">15</span>, <span class="dt">trafo =</span> function(x) <span class="dv">2</span>^x,
    <span class="dt">requires =</span> <span class="kw">quote</span>(classif.svm.kernel ==<span class="st"> "radial"</span> &amp;<span class="st"> </span>selected.learner ==<span class="st"> "classif.svm"</span>)),
  <span class="kw">makeIntegerParam</span>(<span class="st">"classif.svm.degree"</span>, <span class="dt">lower =</span> <span class="dv">1</span>, <span class="dt">upper =</span> <span class="dv">4</span>,
    <span class="dt">requires =</span> <span class="kw">quote</span>(classif.svm.kernel ==<span class="st"> "polynomial"</span> &amp;<span class="st"> </span>selected.learner ==<span class="st"> "classif.svm"</span>)),
  <span class="kw">makeDiscreteParam</span>(<span class="st">"classif.svm.kernel"</span>, <span class="dt">values =</span> <span class="kw">c</span>(<span class="st">"radial"</span>, <span class="st">"polynomial"</span>, <span class="st">"linear"</span>),
    <span class="dt">require =</span> <span class="kw">quote</span>(selected.learner ==<span class="st"> "classif.svm"</span>))
)</code></pre></div>
<p>Next, we create the control objects and a suitable learner, combining <code><a href="http://www.rdocumentation.org/packages/mlr/topics/makeFilterWrapper">makeFilterWrapper()</a></code> with <code><a href="http://www.rdocumentation.org/packages/mlr/topics/makeModelMultiplexer">makeModelMultiplexer()</a></code>. (Please refer to the <a href="/mlr-tutorial/devel/html/advanced_tune/index.html#tuning-across-whole-model-spaces-with-modelmultiplexer">advanced tuning chapter of the mlr tutorial</a> for details.) Afterwards, we can run <code><a href="http://www.rdocumentation.org/packages/mlr/topics/tuneParams">tuneParams()</a></code> and check the results.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ctrl =<span class="st"> </span><span class="kw"><a href="../../reference/makeMBOControl.html">makeMBOControl</a></span>()
ctrl =<span class="st"> </span><span class="kw"><a href="../../reference/setMBOControlTermination.html">setMBOControlTermination</a></span>(ctrl, <span class="dt">iters =</span> iters)
lrn =<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/mlr/topics/makeFilterWrapper">makeFilterWrapper</a></span>(<span class="kw"><a href="http://www.rdocumentation.org/packages/mlr/topics/makeModelMultiplexer">makeModelMultiplexer</a></span>(<span class="kw">list</span>(<span class="st">"classif.svm"</span>, <span class="st">"classif.naiveBayes"</span>)))
tune.ctrl =<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/mlr/topics/makeTuneControlMBO">makeTuneControlMBO</a></span>(<span class="dt">mbo.control =</span> ctrl)

res =<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/mlr/topics/tuneParams">tuneParams</a></span>(lrn, iris.task, cv3, <span class="dt">par.set =</span> par.set, <span class="dt">control =</span> tune.ctrl, <span class="dt">show.info =</span> <span class="ot">FALSE</span>)
<span class="kw">print</span>(res)
## Tune result:
## Op. pars: fw.method=variance; fw.perc=0.694; selected.learner=classif.naiv...
## mmce.test.mean=0.0466667
res$x
## $fw.method
## [1] "variance"
## 
## $fw.perc
## [1] 0.6936187
## 
## $selected.learner
## [1] "classif.naiveBayes"
res$y
## mmce.test.mean 
##     0.04666667
op =<span class="st"> </span><span class="kw">as.data.frame</span>(res$opt.path)
<span class="kw">plot</span>(<span class="kw">cummin</span>(op$mmce.test.mean), <span class="dt">type =</span> <span class="st">"l"</span>, <span class="dt">ylab =</span> <span class="st">"mmce"</span>, <span class="dt">xlab =</span> <span class="st">"iteration"</span>)</code></pre></div>
<p><img src="machine_learning_with_mlrmbo_files/figure-html/pipeline_tuning-1.svg" width="672"></p>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#purpose">Purpose</a></li>
      <li><a href="#mlr"><code>mlr</code></a></li>
      <li><a href="#preparations">Preparations</a></li>
      <li><a href="#custom-objective-function-to-evaluate-performance">1 Custom objective function to evaluate performance</a></li>
      <li><a href="#using-mlrs-tuning-interface">2 Using <code>mlr</code>’s tuning interface</a></li>
      <li><a href="#hierarchical-mixed-space-optimization">Hierarchical mixed space optimization</a></li>
      <li><a href="#parallelization-and-multi-point-proposals">Parallelization and multi-point proposals</a></li>
      <li><a href="#usecase-pipeline-configuration">Usecase: Pipeline configuration</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Bernd Bischl, Jakob Bossek, Jakob Richter, Daniel Horn, Michel Lang, Janek Thomas.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
